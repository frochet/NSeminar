 \documentclass[10pt,article]{IEEEtran}
\usepackage{cite}
\usepackage[cmex10]{amsmath}
\usepackage{array}
\usepackage{url}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{verbatim}
\usepackage{lmodern}
\begin{document}
\title{Automated troubleshooting toolset for SDNs}

\author{\IEEEauthorblockN{Knop Thibaut, Rochet Florentin\\}
\IEEEauthorblockA{EPL,
UCL\\
Louvain-la-Neuve, Belgique\\
\{thibaut.knop,florentin.rochet\}@student.uclouvain.be}}


\maketitle
\begin{abstract}
TODO
\end{abstract}

\begin{IEEEkeywords}
TODO
\end{IEEEkeywords}

\section{Introduction}

For many years, the debugging have always been one of the major concerns in network maintenance. In order to localize problems into the network, operators usually use a narrow toolset, composed of traditional tools as \verb@ping@, \verb@traceroute@ and \verb@SNMP@ agents\cite{zeng2012automatic}.\\
Hopefully, this difficult and time-consuming\cite{zeng2012automatic} process could change, given the deployment of Software-Defined Networks. In a nutshell, SDNs are based on the separation between control- and data planes, which offer the opportunity of programmable networks\cite{mckeown2008openflow}. Those SDNs are composed of a network of switches managed by a logically-centralized controller, whose role is to (un-)install rules into the flow table of the switches, to read traffic statistics and respond to the network activity.\\
However, and because SDNs allows different operators and developers to dynamically program the same network, the complexity of software will increase\cite{Sherwood:2010:PNT:1924943.1924969} and potentially the numbers of bugs.
To minimise the trade-off between introducing new functionality and  increase the number of bugs in the network, there is a serious need for a complete and effective automated testing toolset, allowing the admins to focus on fixing the issues instead of localizing them. In traditional network architecture, it is almost impossible to create such an automated test suite, due to the complexity of \textit{knowing the operator's intent} and \textit{checking network behavior against intent}\cite{Heller:2013:LSL:2491185.2491197} (for more information about how traditional networks could be extended to support automated troubleshooting, please refer to \cite{Heller:2013:LSL:2491185.2491197}).\\
As we will explain (see Section~\ref{layering}), we use the different layers of the SDN stack to review the available tools for automated troubleshooting. Note that the methodology and the structure of this paper is influenced from the one used in\cite{Heller:2013:LSL:2491185.2491197}. It indeed seems the better way to articulate and present the different tools destined to localize the problems and their cause in an automated way.
The paper is structured as follow : first we recall the different layers of the SDN stack, and how it can be leveraged to provide automated troubleshooting for SDNs, then we present different existing tools by positioning them regarding the SDN layering, and we eventually conclude.

\section{SDN layering, the key used to an automated troubleshooting}\label{layering}
 % Expliquer ici la stack SDN (decomposition en layer) et donner l'intuition concernant la plus grande facilité pour remonter à l'origine d'un probleme.
Finding and solving network bugs are not the aim of SDN, but we can use it to re-think the way we troubleshoot networks.\\ The SDN architecture is decomposed into  layers, those layers can be represented in a two dimensionnal array. As you can see on Figure \ref{layers}, we have the two main layers called \textit{State layers} and \textit{Code layers}. The state layers hold a representation of the network's configuration for each parts of the network architecture. The code layers implement logic to maintain the mapping between two state layers. Each states layers should verify the equivalence properties, which means that each of them should correctly mapping every other state layer. The idea is that, for each policy, if the state layers are correctly mapped among each other, then the policy is  set and acts like it should.\\
On the Figure \ref{layers}, you have the following elements. \\
\textbf{Policy} - Policies are set up by the network administrator to configure the Logical View. These policies can be routing, access control or QoS policies. They are written inside a control application. See \cite{...} for exemple.
\\
\textbf{Logical View} - Abstract representation of the network which aims to make things easier for the control application to create policies. A mapping between the Logical View and one or more Physical View are done by Network Hypervisor.\\
\textbf{Physical View} - This is a correspondance with the real network element, a representation of it handled by the network OS. The protocol used to configure the network element is one like OpenFlow \cite{...https://www.opennetworking.org/}. A physical View has thus a one-to-one mapping with a real network element.
\\
\textbf{Device State} - State of the network element maintened by its firmware.
\\
\textbf{Hardware} - Network element. \\

Thanks to the SDN stack, one can first build a tool to check consistency between state layers in order to identify on which part of the network architecture a bug is happening (in which \textit{code layer}). Then, when the layer is identified, an other tool take over to localize the issue inside the code layer. We will see in section \ref{Network Troubleshooting - Tools} which kind of tools could be used to handle this bug hunting. Tools to find the code layer concerned by the issue and tools which operate inside the code layer, to find the cause of the bug.

\begin{figure}
\centering
\includegraphics[scale=0.65]{layers.png}
\label{layers}
\caption{SDN architecture - This image come from \cite{Heller:2013:LSL:2491185.2491197}}
\end{figure}
\section{Network Troubleshooting - Tools}
\label{Network Troubleshooting - Tools}
\subsection{Network Debugger (NDB)}

\subsection{VeriFlow}
If the actual behavior of the network does not correspond to the policy, then the issue can potentially be found in the erroneous correspondance between the \textit{device state layer} and the \textit{policy layer}. There exist different tools to verify this hypothesis. The one we discuss here have the advantage to verify some network invariants in real-time. Other tools as Anteater and Header Space Analysis (HSA) that are also used in the same purpose carry out the static analysis of snapshots of the network data-plane state\cite{Kazemian:2012:HSA:2228298.2228311}\cite{Mai:2011:DDP:2018436.2018470}. Since SDN controllers are capable of installing around 30.000 flows per second while maintaining less than 10 ms delay for the installation, it is absolutely not enough to have tools that check for network invariant with a latency of the order of seconds \cite{Khurshid:2013:VVN:2482626.2482630}.\\
VeriFlow acts as a proxy in between the SDN controller and the switches and this proxy verifies some common network invariants at each forwarding rule installation with a very high speed. In order to achieve a 7ms delay inflation with regards to traditional TCP connections\footnote{Test configuration : 20 nodes OpenFlow network sing Mininet and a NOX controller\cite{Khurshid:2013:VVN:2482626.2482630} }, VeriFlow slices the network into equivalences classes, then builds a virtual forwarding graph for each ones using a trie structure, and finally checks invariants by traversing those graph with a depth-first search approach. Note that VeriFlow allows to spotting network issues before they reach the network, which is very valuable.\\
As limitations, we can note that presently, VeriFlow only checks for reachability invariants, and that it is not suitable for multiple/distributed controller \cite{Khurshid:2013:VVN:2482626.2482630}.

\subsection{SOFT - \textit{Systematic OpenFlow Testing}}

\subsection{NICE - \textit{No Bugs in Controller Execution}}

Following the SDN layering technique, once the erroneous 2-layers correspondance has been determined, another tool can be used to spot the bug more precisely, either in the controller software or in the firmware running on the switches.\\
The NICE tool is used to produce traces leading to a bug, by systematically exploring the set of possible states of the system (including controller, switches and hosts) and checking them regards to some network invariants\cite{Canini:2012:NWT:2228298.2228312}. What makes this contribution to OpenFlow verification a real asset is its ability to deal with a unbound space state. The real challenge for testing openFlow applications is the scalability.

\subsection{FlowChecker}




\section{Conclusion}


\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,draft}

\end{document}
